<#
.SYNOPSIS
This script performs read and write tests against PremiumV2_LRS disk storage attached to Ubuntu Linux VMs within a region to determine network throughput and storage latency.

Note: This script depends on the parquetfiles.log file inventory file being generated by the CSE script running on the server/storage VMs.

.NOTES
Author: Azure
Copyright (c) Microsoft Corporation.
Licensed for your reference purposes only on an as is basis, without warranty of any kind.
#>

param
(
    [Parameter(Mandatory = $true)]
    [string]$accountId, # client Id of user managed identity for the resource subscription
    [string]$subscriptionId, # subscription Id of resource subscription
    [string]$clientVmPrefix, # naming prefix of client/worker VMs, for testing client vs server in the topology
    [string]$serverVmPrefix, # naming prefix of server VMs, for finding all server VMs in the resource group, parquet file download servers
    [string]$replServerVmPrefix,  # naming prefix of replication server VM, for finding server VM in the resource group, parquet file upload server
    [string]$parquetfilesListEndpoint # file URL on server VM with list of files to download from server VM
)

    function Get-Percentile {
        param (
        [float[]]$numbers,
        [float]$percentile = 90
        )

		$sortedNumbers = $numbers | Sort-Object
		$index = [math]::Ceiling(($percentile / 100) * $sortedNumbers.Count) - 1
		return $sortedNumbers[$index]
    }

# Manifest file Powershell script parameters

#====================================
#  Declare check metadata
#====================================

# Declare check metadata
New-Variable -Option Constant -Name CheckResultMetricsName -Value 'snowflakechecktool' # fill this field for the metric name when emitting check result
New-Variable -Option Constant -Name CheckToolName -Value 'snowflake_readwrite_pv2.ps1' # fill  field with check tool's file name

$startTime = (Get-Date).ToUniversalTime().ToString("o")
# Common logic shared across checks
#====================================

# Source common function files by searching either 
# (1)script directory: location of this script
# (2)package directory: root location of this package (2-levels up)
$scriptDir = $MyInvocation.MyCommand.Path | Split-Path -Parent | Join-Path -ChildPath "common"
$packageDir = $scriptDir | Split-Path -Parent | Split-Path -Parent | Split-Path -Parent | Join-Path -ChildPath "common"

$scriptDirFileCount = Get-ChildItem -Path $scriptDir -Filter '*.ps1' -ErrorAction SilentlyContinue
$packageDirFileCount = Get-ChildItem -Path $packageDir -Filter '*.ps1' -ErrorAction SilentlyContinue
New-Variable -Option Constant -Name CheckStartTime -Value $startTime

Remove-Variable -Name @('Scenario', 'CheckCaseName') -ErrorAction Ignore 

#====================================

if ( $null -ne $scriptDirFileCount) {
    $commonLibPath = $scriptDir
}
elseif ( $null -ne $packageDirFileCount) {
    $commonLibPath = $packageDir
}
else {
    $checkEndTime = (Get-Date).ToUniversalTime().ToString("o")
    $checkResult = 3
    $logHashTable = [ordered]@{ 
        "Type"           = 'Metrics'
        "Message"        = 'Cannot find common directory containing helper functions. Exiting.'
        "CheckToolName"  = $CheckToolName
        "MetricsName"    = $CheckResultMetricsName
        "MetricsUnit"    = 'CheckResult'
        "MetricsValue"   = $checkResult
        "CheckStartTime" = $CheckStartTime
        "CheckEndTime"   = $checkEndTime
    } 
    $logHashTable | ConvertTo-Json | Write-LogInformation
    exit $checkResult
}

. $(Join-Path $commonLibPath "Constants.ps1");
. $(Join-Path $commonLibPath "Utils.ps1");
. $(Join-Path $commonLibPath "Log.ps1");
. $(Join-Path $commonLibPath "InstallPackages.ps1");
. $(Join-Path $commonLibPath "AggregateUtils.ps1");


# Check variables required by log.sh functions
$requiredVarName = @('CheckResultMetricsName', 'CheckToolName', 'CheckStartTime')
if (!(Confirm-SetVariable -VariableNames $requiredVarName)) {
    $checkEndTime = Get-CurrentTimestamp
    Write-LogCheckResultAndExit -Message 'Required log parameters are not set. Exiting.' -MetricsValue $CHECK_FAILURE_INVALID_ARG -CheckEndTime $checkEndTime
}

# Install Az modules
$installRetCode = Install-ModuleWithChecks -ModuleName 'Az.Accounts' -RetryTime 2 -SleepSec 5
if (!$installRetCode) {
    $checkEndTime = Get-CurrentTimestamp
    Write-LogError -Message "Failed to install Az.Accounts module." -CheckEndTime $checkEndTime
    Write-LogCheckResultAndExit -MetricsValue $CHECK_FAILURE_DEPENDENT_TOOL -CheckEndTime $checkEndTime
}

$installRetCode = Install-ModuleWithChecks -ModuleName 'Az.Compute' -RetryTime 2 -SleepSec 5
if (!$installRetCode) {
    $checkEndTime = Get-CurrentTimestamp
    Write-LogError -Message "Failed to install Az.Compute module." -CheckEndTime $checkEndTime
    Write-LogCheckResultAndExit -MetricsValue $CHECK_FAILURE_DEPENDENT_TOOL -CheckEndTime $checkEndTime
}

$installRetCode = Install-ModuleWithChecks -ModuleName 'Az.Monitor' -RetryTime 2 -SleepSec 5
if (!$installRetCode) {
    $checkEndTime = Get-CurrentTimestamp
    Write-LogError -Message "Failed to install Az.Monitor module." -CheckEndTime $checkEndTime
    Write-LogCheckResultAndExit -MetricsValue $CHECK_FAILURE_DEPENDENT_TOOL -CheckEndTime $checkEndTime
}

$installRetCode = Install-ModuleWithChecks -ModuleName 'Az.Storage' -RetryTime 2 -SleepSec 5
if (!$installRetCode) {
    $checkEndTime = Get-CurrentTimestamp
    Write-LogError -Message "Failed to install Az.Storage module." -CheckEndTime $checkEndTime
    Write-LogCheckResultAndExit -MetricsValue $CHECK_FAILURE_DEPENDENT_TOOL -CheckEndTime $checkEndTime
}

# Import Az modules
try{
    Import-Module Az.Accounts
    Write-LogInformation -Message "Az.Accounts module imported successfully."
}
catch{
    $checkEndTime = Get-CurrentTimestamp
    Write-LogError -Message "Failed to import Az.Accounts module. Exception: $_." -CheckEndTime $checkEndTime
    Write-LogCheckResultAndExit -MetricsValue $CHECK_FAILURE_DEPENDENT_TOOL -CheckEndTime $checkEndTime
}
try{
    Import-Module Az.Compute
    Write-LogInformation -Message "Az.Compute module imported successfully."
}
catch{
    $checkEndTime = Get-CurrentTimestamp
    Write-LogError -Message "Failed to import Az.Compute module. Exception: $_." -CheckEndTime $checkEndTime
    Write-LogCheckResultAndExit -MetricsValue $CHECK_FAILURE_DEPENDENT_TOOL -CheckEndTime $checkEndTime
}

try{
    Import-Module Az.Monitor
    Write-LogInformation -Message "Az.Monitor module imported successfully."
}
catch{
    $checkEndTime = Get-CurrentTimestamp
    Write-LogError -Message "Failed to import Az.Monitor module. Exception: $_." -CheckEndTime $checkEndTime
    Write-LogCheckResultAndExit -MetricsValue $CHECK_FAILURE_DEPENDENT_TOOL -CheckEndTime $checkEndTime
}

try{
    Import-Module Az.Storage
    Write-LogInformation -Message "Az.Storage module imported successfully."
}
catch{
    $checkEndTime = Get-CurrentTimestamp
    Write-LogError -Message "Failed to import Az.Storage module. Exception: $_." -CheckEndTime $checkEndTime
    Write-LogCheckResultAndExit -MetricsValue $CHECK_FAILURE_DEPENDENT_TOOL -CheckEndTime $checkEndTime
}

#=========================================
# Customized check logic - Snowflake
#=========================================

# Common items for client and server VMs
$hostName = [Environment]::MachineName
$OSTemp = [System.IO.Path]::GetTempPath()

# Connect to Azure and set context as UMI
Connect-AzAccount -identity -AccountId $accountId -SubscriptionId $subscriptionId

#===============================================================================================
#===============================================================================================
# Read process for check tool
#===============================================================================================
#===============================================================================================

#=========================================
# Cleanup operations of previous downloaded temp files
If ($hostName -like "$clientVmPrefix*") {
    Write-LogInformation -Message "Client VM type on $hostName"
	Write-LogInformation -Message "Perform .parquet file cleanup before downloads on $hostName"
	cd /tmp/parquet
	rm *.parquet
	rm *.txt
	rm *.log
}

# Prepare parquet testing directory if not exist
$parquetDir = "${OSTemp}parquet"
If (!(Test-Path -Path $parquetDir)) {
    New-Item -ItemType Directory -Path $parquetDir
}

#=========================================
# Create file hash comparison CSV if not exist

If ($hostName -like "$clientVmPrefix*") {
    Write-LogInformation -Message "Client VM type on $hostName"
	Write-LogInformation -Message "Perform file hash file create if not exist on $hostName"

    $fileHashCSVFilePath = "${OSTemp}parquet/fileHash.csv"

    If (-not (Test-Path $fileHashCSVFilePath)) {
	    $header = "file,hash"
        Set-Content -Path $fileHashCSVFilePath -Value $header
        $fileHashCSVFileExist = "false"
    } else {
        $fileHashCSVFileExist = "true"
    }
}

#=========================================
# Perform read test (downloads) to client VMs
$curlBin = "/usr/local/bin/curl"

If ($hostName -like "$clientVmPrefix*") {
    Write-LogInformation -Message "Client VM type on $hostName"
    Write-LogInformation -Message "Perform read test (downloads) to client VMs on $hostName"

    try {

	    # Get server names like serverVmPrefix and add to array
        $vmMetadata=Get-InstanceMetadata
        $resourceGroupName=$vmMetadata.compute.resourceGroupName
        $serverAccountsFilter = Get-AzVM | Where-Object { $_.ResourceGroupName -like "$resourceGroupName" -and $_.Name -like "$serverVmPrefix*" }
        $serverAccounts = $serverAccountsFilter | Select-Object -ExpandProperty Name

	    $fileURLsString=@()
	    ForEach ($itemServer in $serverAccounts) {

		    # Get all filename strings from the server accounts and add to fileArray
		    cd "${OSTemp}parquet"
		    & $curlBin -s $parquetfilesListEndpoint -o "${OSTemp}parquet/parquetfiles.log"
		    $fileArray = Get-Content "${OSTemp}parquet/parquetfiles.log"
            
		    ForEach ($itemFile in $fileArray) {
			    $fileURLsString += "`"http://${itemServer}.privatelink.snowflake.com/${itemFile}`""
		    }
	    }
	    $fileURLsString > "${OSTemp}parquet/curlConfig.txt"
	    shuf "${OSTemp}parquet/curlConfig.txt" > "${OSTemp}parquet/shufCurlConfig.txt"

	    Write-LogInformation -Message "Downloading parquet files with Curl START on $hostName"

        # Curl start time
	    $curlStartTime = Get-Date

        # Download with Curl all files parallel command with progress meter output to log file (only works with /dev/null output)
        cd "${OSTemp}parquet"
	    $curlDownloadsLog = "${OSTemp}parquet/curlDownloads.log"
	    cat "${OSTemp}parquet/shufCurlConfig.txt" | xargs -n 1 -P 10 $curlBin -O --write-out "%{url_effective} %{size_download} %{speed_download} bytes/sec\n" >> "$curlDownloadsLog" -s
	
	    Write-LogInformation -Message "Downloading parquet files with Curl END on $hostName"

        # Curl end time
	    $curlEndTime = Get-Date

	    $curlTimeSpan = New-TimeSpan -Start $curlStartTime -End $curlEndTime
	    $curlTimeElapsed = $curlTimeSpan.TotalSeconds
	
	    # Sleep for 15 seconds between file downloads and hash comparisons
	    Write-LogInformation -Message "Sleeping 15 seconds between file downloads and file hash comparisons on $hostName"	
	    Start-Sleep -Seconds 15
    }
    catch {
	    Write-LogError -Message "Unexpected exception occured when running the checktool" -CheckEndTime Get-CurrentTimestamp
	    $checkEndTime = Get-CurrentTimestamp
	    Write-LogCheckResultAndExit -MetricsValue $CHECK_FAILURE_WITH_ERROR -CheckEndTime $checkEndTime
    }
}
		
#=========================================
# Perform file hash comparison on client VMs

If ($hostName -like "$clientVmPrefix*") {
	Write-LogInformation -Message "Client VM type on $hostName"
	Write-LogInformation -Message "Perform file hash comparison on client VMs"
	
    try {
	
        # File hash writing
        If ($fileHashCSVFileExist -eq "false") {

            ForEach ($itemFile in $fileArray) {
                $joinFileHash = Join-Path -Path "${OSTemp}parquet" -ChildPath $itemFile
		        $localFileHash = (Get-FileHash $joinFileHash -Algorithm MD5).Hash

		        # write the file hash into a .csv file that can be compared against going forward
		        Add-Content -Path $fileHashCSVFilePath -Value "$itemFile,$localFileHash"
            }
        } elseif ($fileHashCSVFileExist -eq "true") {

            $importCSV = Import-Csv -Path $fileHashCSVFilePath
            # Convert CSV to a Hashtable for fast lookup
            $fileHashCSVHashTable = @{}
            foreach ($row in $importCSV) {
                $fileHashCSVHashTable[$row.file] = $row.hash
            }

            # Directory where downloaded files are stored
            $parquetFilesFolder = "${OSTemp}parquet"

            # Get all downloaded files
            $parquetFiles = Get-ChildItem -Path $parquetFilesFolder -Filter "*.parquet" -File

            ForEach ($parquetFile in $parquetFiles) {
                $parquetFilePath = $parquetFile.FullName
                $parquetFileName = $parquetFile.Name

                if ($fileHashCSVHashTable.ContainsKey($parquetFileName)) {
                    $computedHash = (Get-FileHash -Path $parquetFilePath -Algorithm MD5).Hash
	                $fileHashCSVHashTableHash = $fileHashCSVHashTable[$parquetFileName]
	                    if ($computedHash -ne $fileHashCSVHashTableHash) {
                            $checkEndTime = Get-CurrentTimestamp
                            Write-LogError -Message "Hashes do NOT match for $parquetFileName Local file: $computedHash - csvFileHash: $fileHashCSVHashTableHash" -CheckEndTime $checkEndTime
				            Write-LogInformation -Message "Perform .parquet file hash CSV file reset on $hostName"
				            cd "${OSTemp}parquet"
				            rm fileHash.csv
                            Write-LogCheckResultAndExit -MetricsValue $CHECK_FAILURE_WITH_ERROR -CheckEndTime $checkEndTime
	                    }
                } else {
                    $checkEndTime = Get-CurrentTimestamp
				    Write-LogError -Message "File does not exist in hash table $parquetFileName" -CheckEndTime $checkEndTime
				    Write-LogInformation -Message "Perform .parquet file hash CSV file reset on $hostName"
				    cd "${OSTemp}parquet"
				    rm fileHash.csv
				    Write-LogCheckResultAndExit -MetricsValue $CHECK_FAILURE_WITH_ERROR -CheckEndTime $checkEndTime
                }
            }
	    }
    }	
    catch {
		    Write-LogError -Message "Unexpected exception occured when running the checktool" -CheckEndTime Get-CurrentTimestamp
		    $checkEndTime = Get-CurrentTimestamp
		    Write-LogCheckResultAndExit -MetricsValue $CHECK_FAILURE_WITH_ERROR -CheckEndTime $checkEndTime
    }
}

#=========================================
# Get network throughput metrics on client VMs

If ($hostName -like "$clientVmPrefix*") {
	Write-LogInformation -Message "Get network throughput metrics"
	
    try {	
	    $curlDownloadsData = Get-Content $curlDownloadsLog
	    $curlTotalDownloadSize = 0
	    $curlTotalDownloadFiles = 0
	    $curlBwArray = @()
	
	    foreach ($line in $curlDownloadsData) {
		    $parts = $line -split ' '
		    if ($parts.Count -ge 2) {
			    $fileSize = [long]$parts[1]
			    $curlTotalDownloadSize += $fileSize
			    $curlTotalDownloadFiles ++
			    $curlBw = ([long]$parts[2] * 8) / 1000000
			    $curlBwArray += $curlBW	
		    }
	    }
        # Total download size using parallel downloads
	    $curlTotalDownloadSizeMB = [math]::Round($curlTotalDownloadSize / 1MB, 2)
        # Total throughput using parallel downloads
	    $curlNetworkThroughputTotal_Parallel = ($curlTotalDownloadSizeMB / $curlTimeElapsed) * 8

        # Curl reported per file throughput (not taking into account parallel requests)
	    $curlBw_Agg = Get-AggregatedMetrics $curlBwArray
	    $curlBwArrayMin = $curlBw_Agg.Min
	    $curlBwArrayMax = $curlBw_Agg.Max
	    $curlBwArrayAvg = $curlBw_Agg.Average
	    $curlBwArrayMed = $curlBw_Agg.Median	
	    $curlBw_P25 = (Get-Percentile -numbers $curlBwArray -percentile 25)
	    $curlBw_P50 = (Get-Percentile -numbers $curlBwArray -percentile 50)
	    $curlBw_P90 = (Get-Percentile -numbers $curlBwArray -percentile 90)
	    $curlBw_P99 = (Get-Percentile -numbers $curlBwArray -percentile 99)
	    $curlBw_P999 = (Get-Percentile -numbers $curlBwArray -percentile 99.9)
	
	    # Log check result
        $status="Success"
        $checkEndTime = Get-CurrentTimestamp
	    Write-LogInformation "Snowflake checktool succeeded - Perform read test - $checkEndTime"

    }
    catch {
        Write-LogError -Message "Unexpected exception occured when running the checktool" -CheckEndTime Get-CurrentTimestamp
	    $checkEndTime = Get-CurrentTimestamp
        Write-LogCheckResultAndExit -MetricsValue $CHECK_FAILURE_WITH_ERROR -CheckEndTime $checkEndTime
    }
}

#=========================================
# Get storage latency metrics from client VMs

If ($hostName -like "$clientVmPrefix*") {
    Write-LogInformation -Message "Client VM type on $hostName"
    Write-LogInformation -Message "Perform data disk storage latency test to server VMs on $hostName"

    try {
	    $DDLatencyAvgArray = @()
	    $DDLatencyMaxArray = @()
	    $DDDiskQueueAvgArray = @()
	    $DDDiskQueueMaxArray = @()
	
	    # Regress 600 seconds to $curlStartTime if less than 60 to allow Get-AzMetric small tests to function (fails if less than 1 minute sample)
	    If ($curlTimeElapsed -lt 60) {
		    Write-LogInformation -Message "Moving curlStartTime back 600 seconds to impact Get-AzMetric on $hostName"
		    $curlStartTime = $curlStartTime.AddSeconds(-600)
			Write-LogInformation -Message "New curlStartTime: $curlStartTime on $hostName"
			Write-LogInformation -Message "New curlEndTime: $curlEndTime on $hostName"
	    }
	
	    ForEach ($itemServerVm in $serverAccounts) {
		    $serverAccountsCount = $serverAccounts.count
		    $resourceGroupName = (Invoke-RestMethod -Headers @{"Metadata"="true"} -Method Get -Uri "http://169.254.169.254/metadata/instance?api-version=2021-02-01").compute.resourceGroupName
		    $serverVm = Get-AzVM -ResourceGroupName $resourceGroupName -Name $itemServerVm
		    $resourceId = $serverVm.Id		
		    $interval = "00:01:00"  # 1 minute granularity
		    $DDLatency = Get-AzMetric -ResourceId $resourceId -MetricName "Data Disk Latency" -TimeGrain $interval -StartTime $curlStartTime -EndTime $curlEndTime	
		    $DDDiskQueue = Get-AzMetric -ResourceId $resourceId -MetricName "Data Disk Queue Depth" -TimeGrain $interval -StartTime $curlStartTime -EndTime $curlEndTime
		    $DDLatencyAvgArray += ($DDLatency.Data | Measure-Object -Property Average -Average).Average
		    $DDLatencyMaxArray += ($DDLatency.Data | Measure-Object -Property Average -Maximum).Maximum
		    $DDDiskQueueAvgArray += ($DDDiskQueue.Data | Measure-Object -Property Average -Average).Average
		    $DDDiskQueueMaxArray += ($DDDiskQueue.Data | Measure-Object -Property Average -Maximum).Maximum
	    }
		    $DDLatencyAvgArrayAvg = ($DDLatencyAvgArray | Measure-Object -Average).Average
		    $DDLatencyMaxArrayMax = ($DDLatencyMaxArray | Measure-Object -Maximum).Maximum
		    $DDDiskQueueAvgArrayAvg = ($DDDiskQueueAvgArray | Measure-Object -Average).Average
		    $DDDiskQueueMaxArrayMax = ($DDDiskQueueMaxArray | Measure-Object -Maximum).Maximum
	
        # Log check result
        $status="Success"
        $checkEndTime = Get-CurrentTimestamp
	    Write-LogInformation "Snowflake checktool succeeded - Storage read latency from server VMs - $checkEndTime"

    }
    catch {
        Write-LogError -Message "Unexpected exception occured when running the checktool" -CheckEndTime Get-CurrentTimestamp
	    $checkEndTime = Get-CurrentTimestamp
        Write-LogCheckResultAndExit -MetricsValue $CHECK_FAILURE_WITH_ERROR -CheckEndTime $checkEndTime
    }
}

#=========================================
# Metrics writing to Kusto

If ($hostName -like "$clientVmPrefix*") {
    Write-LogInformation -Message "Metrics writing/uploading on $hostName"
	Write-LogInformation -Message "Data for metrics: Total Download Size - $curlTotalDownloadSizeMB on $hostName"
	Write-LogInformation -Message "Data for metrics: Time Elapsed - $curlTimeElapsed on $hostName"
	Write-LogInformation -Message "Data for metrics: Total Download Files - $curlTotalDownloadFiles on $hostName"

    try {

	    # Network throughput from client VM
        Write-LogMetricsWithCustomProps -MetricsName "NetworkThroughputTotal_Parallel" -MetricsUnit "Mbps" -MetricsValue $curlNetworkThroughputTotal_Parallel -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostName }
	    Write-LogMetricsWithCustomProps -MetricsName "NetworkThroughputFile_Minimum" -MetricsUnit "Mbps" -MetricsValue $curlBwArrayMin -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostName }
	    Write-LogMetricsWithCustomProps -MetricsName "NetworkThroughputFile_Maximum" -MetricsUnit "Mbps" -MetricsValue $curlBwArrayMax -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostName }
	    Write-LogMetricsWithCustomProps -MetricsName "NetworkThroughputFile_Average" -MetricsUnit "Mbps" -MetricsValue $curlBwArrayAvg -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostName }
	    Write-LogMetricsWithCustomProps -MetricsName "NetworkThroughputFile_Median" -MetricsUnit "Mbps" -MetricsValue $curlBwArrayMed -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostName }
	    Write-LogMetricsWithCustomProps -MetricsName "NetworkThroughputFile_P25" -MetricsUnit "Mbps" -MetricsValue $curlBw_P25 -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostName }
	    Write-LogMetricsWithCustomProps -MetricsName "NetworkThroughputFile_P50" -MetricsUnit "Mbps" -MetricsValue $curlBw_P50 -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostName }
	    Write-LogMetricsWithCustomProps -MetricsName "NetworkThroughputFile_P90" -MetricsUnit "Mbps" -MetricsValue $curlBw_P90 -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostName }
	    Write-LogMetricsWithCustomProps -MetricsName "NetworkThroughputFile_P99" -MetricsUnit "Mbps" -MetricsValue $curlBw_P99 -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostName }
	    Write-LogMetricsWithCustomProps -MetricsName "NetworkThroughputFile_P999" -MetricsUnit "Mbps" -MetricsValue $curlBw_P999 -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostName }

	    # Storage read latency from client VM	
        Write-LogMetricsWithCustomProps -MetricsName "StorageLatency_DataDisk_Avg_Avg" -MetricsUnit $METRIC_UNIT_MilliSeconds -MetricsValue $DDLatencyAvgArrayAvg -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostname }
        Write-LogMetricsWithCustomProps -MetricsName "StorageLatency_DataDisk_Max_Max" -MetricsUnit $METRIC_UNIT_MilliSeconds -MetricsValue $DDLatencyMaxArrayMax -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostname }
        Write-LogMetricsWithCustomProps -MetricsName "StorageDiskQueue_DataDisk_Avg_Avg" -MetricsUnit "Queued Requests" -MetricsValue $DDDiskQueueAvgArrayAvg -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostname }
        Write-LogMetricsWithCustomProps -MetricsName "StorageDiskQueue_DataDisk_Max_Max" -MetricsUnit "Queued Requests" -MetricsValue $DDDiskQueueMaxArrayMax -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostname }

        # Log check result
        $status="Success"
        $checkEndTime = Get-CurrentTimestamp
	    Write-LogInformation "Snowflake checktool succeeded - Metrics generation - $checkEndTime"
		
		# Sleep for 15 seconds between read downloads and write uploads
	    Write-LogInformation -Message "Sleeping 15 seconds between read downloads and write uploads on $hostName"	
	    Start-Sleep -Seconds 15

    }
    catch {
        Write-LogError -Message "Unexpected exception occured when running the checktool" -CheckEndTime Get-CurrentTimestamp
	    $checkEndTime = Get-CurrentTimestamp
        Write-LogCheckResultAndExit -MetricsValue $CHECK_FAILURE_WITH_ERROR -CheckEndTime $checkEndTime
    }
}

#===============================================================================================
#===============================================================================================
# Write process for check tool
#===============================================================================================
#===============================================================================================


#=========================================
# Perform write test (uploads) to repl server VMs

If ($hostName -like "$clientVmPrefix*") {
    Write-LogInformation -Message "Client VM type on $hostName"
    Write-LogInformation -Message "Perform write test (uploads) to repl server VMs on $hostName"

    # testing to sleep for 300 seconds to allow script update in place
    start-sleep -seconds 300

    try {

	    # Get repl server names like replServerVmPrefix and add to array
        $vmMetadata=Get-InstanceMetadata
        $resourceGroupName=$vmMetadata.compute.resourceGroupName
        $replServerAccountsFilter = Get-AzVM | Where-Object { $_.ResourceGroupName -like "$resourceGroupName" -and $_.Name -like "$replServerVmPrefix*" }
        $replServerAccounts = $replServerAccountsFilter | Select-Object -ExpandProperty Name

	    $replFileURLsString=@()
	    ForEach ($itemReplServer in $replServerAccounts) {

		    # Get all filename strings from the local disk and add to fileArray
		    cd "${OSTemp}parquet"
			
			# Directory where downloaded files are stored
            $parquetFilesFolder = "${OSTemp}parquet"
            # Get all downloaded files
            $parquetFiles = Get-ChildItem -Path $parquetFilesFolder -Filter "*.parquet" -File

		    ForEach ($itemReplFile in $parquetFiles) {
			    $replFileURLsString += "`"$itemReplFile`" `"http://${itemReplServer}.privatelink.snowflake.com/`" `"-w %{url_effective} %{size_upload} %{speed_upload} bytes/sec\n`" `"-s`""
		    }
	    }
	    $replFileURLsString > "${OSTemp}parquet/curlConfigUp.txt"

	    Write-LogInformation -Message "Uploading parquet files with Curl START on $hostName"

        # Curl start time
	    $curlStartTime = Get-Date

        # Upload with Curl all files parallel command with progress meter output to log file (only works with /dev/null output)
        cd "${OSTemp}parquet"
        $curlUploadsLog = "${OSTemp}parquet/curlUploads.log"
		cat "${OSTemp}parquet/curlConfigUp.txt" | xargs -n 4 -P 10 $curlBin -s -o /dev/null -T >> curlUploads.log

	    Write-LogInformation -Message "Uploading parquet files with Curl END on $hostName"

        # Curl end time
	    $curlEndTime = Get-Date

	    $curlTimeSpan = New-TimeSpan -Start $curlStartTime -End $curlEndTime
	    $curlTimeElapsed = $curlTimeSpan.TotalSeconds
	
	    # Sleep for 15 seconds between file uploads and metrics generation
	    Write-LogInformation -Message "Sleeping 15 seconds between file uploads and metrics generation on $hostName"	
	    Start-Sleep -Seconds 15
    }
    catch {
	    Write-LogError -Message "Unexpected exception occured when running the checktool" -CheckEndTime Get-CurrentTimestamp
	    $checkEndTime = Get-CurrentTimestamp
	    Write-LogCheckResultAndExit -MetricsValue $CHECK_FAILURE_WITH_ERROR -CheckEndTime $checkEndTime
    }
}

#=========================================
# Get network throughput metrics on client VMs for uploads to repl server

If ($hostName -like "$clientVmPrefix*") {
	Write-LogInformation -Message "Get network throughput metrics for uploads"
	
    try {	
	
	    $curlUploadsData = Get-Content $curlUploadsLog
	    $curlTotalUploadSize = 0
	    $curlTotalUploadFiles = 0
	    $curlBwArrayUp = @()
	
	    foreach ($line in $curlUploadsData) {	
		    $parts = $line -split "\s+"
		    if ($parts.Count -ge 2) {
			    $fileSize = [int]$parts[2]
			    $curlTotalUploadSize += $fileSize
			    $curlTotalUploadFiles ++
			    $curlBwUp = ([int]$parts[3] * 8) / 1000000
			    $curlBwArrayUp += $curlBwUp	
		    }
	    }	
	
        # Total upload size using parallel uploads
	    $curlTotalUploadSizeMB = [math]::Round($curlTotalUploadSize / 1MB, 2)
        # Total throughput using parallel uploads
	    $curlNetworkThroughputTotalUp_Parallel = ($curlTotalUploadSizeMB / $curlTimeElapsed) * 8

        # Curl reported per file throughput (not taking into account parallel requests)
	    $curlBw_AggUp = Get-AggregatedMetrics $curlBwArrayUp
	    $curlBwArrayUpMin = $curlBw_AggUp.Min
	    $curlBwArrayUpMax = $curlBw_AggUp.Max
	    $curlBwArrayUpAvg = $curlBw_AggUp.Average
	    $curlBwArrayUpMed = $curlBw_AggUp.Median	
	    $curlBwUp_P25 = (Get-Percentile -numbers $curlBwArrayUp -percentile 25)
	    $curlBwUp_P50 = (Get-Percentile -numbers $curlBwArrayUp -percentile 50)
	    $curlBwUp_P90 = (Get-Percentile -numbers $curlBwArrayUp -percentile 90)
	    $curlBwUp_P99 = (Get-Percentile -numbers $curlBwArrayUp -percentile 99)
	    $curlBwUp_P999 = (Get-Percentile -numbers $curlBwArrayUp -percentile 99.9)
	
	    # Log check result
        $status="Success"
        $checkEndTime = Get-CurrentTimestamp
	    Write-LogInformation "Snowflake checktool succeeded - Perform read test - $checkEndTime"

    }
    catch {
        Write-LogError -Message "Unexpected exception occured when running the checktool" -CheckEndTime Get-CurrentTimestamp
	    $checkEndTime = Get-CurrentTimestamp
        Write-LogCheckResultAndExit -MetricsValue $CHECK_FAILURE_WITH_ERROR -CheckEndTime $checkEndTime
    }
}

#=========================================
# Get storage latency metrics from client VMs for repl server

If ($hostName -like "$clientVmPrefix*") {
    Write-LogInformation -Message "Client VM type on $hostName"
    Write-LogInformation -Message "Perform data disk storage latency test to repl server VMs on $hostName"

    try {
	    $replDDLatencyAvgArray = @()
	    $replDDLatencyMaxArray = @()
	    $replDDDiskQueueAvgArray = @()
	    $replDDDiskQueueMaxArray = @()
	
	    # Regress 600 seconds to $curlStartTime if less than 60 to allow Get-AzMetric small tests to function (fails if less than 1 minute sample)
	    If ($curlTimeElapsed -lt 60) {
		    Write-LogInformation -Message "Moving curlStartTime back 600 seconds to impact Get-AzMetric on $hostName"
		    $curlStartTime = $curlStartTime.AddSeconds(-600)
	    }
	
	    ForEach ($itemReplServerVm in $replServerAccounts) {
		    $replServerAccountsCount = $replServerAccounts.count
		    $resourceGroupName = (Invoke-RestMethod -Headers @{"Metadata"="true"} -Method Get -Uri "http://169.254.169.254/metadata/instance?api-version=2021-02-01").compute.resourceGroupName
		    $replServerVm = Get-AzVM -ResourceGroupName $resourceGroupName -Name $itemReplServerVm
		    $resourceId = $replServerVm.Id		
		    $interval = "00:01:00"  # 1 minute granularity
		    $replDDLatency = Get-AzMetric -ResourceId $resourceId -MetricName "Data Disk Latency" -TimeGrain $interval -StartTime $curlStartTime -EndTime $curlEndTime	
		    $replDDDiskQueue = Get-AzMetric -ResourceId $resourceId -MetricName "Data Disk Queue Depth" -TimeGrain $interval -StartTime $curlStartTime -EndTime $curlEndTime
		    $replDDLatencyAvgArray += ($replDDLatency.Data | Measure-Object -Property Average -Average).Average
		    $replDDLatencyMaxArray += ($replDDLatency.Data | Measure-Object -Property Average -Maximum).Maximum
		    $replDDDiskQueueAvgArray += ($replDDDiskQueue.Data | Measure-Object -Property Average -Average).Average
		    $replDDDiskQueueMaxArray += ($replDDDiskQueue.Data | Measure-Object -Property Average -Maximum).Maximum
	    }
		    $replDDLatencyAvgArrayAvg = ($replDDLatencyAvgArray | Measure-Object -Average).Average
		    $replDDLatencyMaxArrayMax = ($replDDLatencyMaxArray | Measure-Object -Maximum).Maximum
		    $replDDDiskQueueAvgArrayAvg = ($replDDDiskQueueAvgArray | Measure-Object -Average).Average
		    $replDDDiskQueueMaxArrayMax = ($replDDDiskQueueMaxArray | Measure-Object -Maximum).Maximum
	
        # Log check result
        $status="Success"
        $checkEndTime = Get-CurrentTimestamp
	    Write-LogInformation "Snowflake checktool succeeded - Storage read latency from server VMs - $checkEndTime"

    }
    catch {
        Write-LogError -Message "Unexpected exception occured when running the checktool" -CheckEndTime Get-CurrentTimestamp
	    $checkEndTime = Get-CurrentTimestamp
        Write-LogCheckResultAndExit -MetricsValue $CHECK_FAILURE_WITH_ERROR -CheckEndTime $checkEndTime
    }
}

#=========================================
# Metrics writing to Kusto for repl server testing

If ($hostName -like "$clientVmPrefix*") {
    Write-LogInformation -Message "Metrics writing/uploading on $hostName"
	Write-LogInformation -Message "Data for metrics: Total Upload Size - $curlTotalUploadSizeMB on $hostName"
	Write-LogInformation -Message "Data for metrics: Time Elapsed - $curlTimeElapsed on $hostName"
	Write-LogInformation -Message "Data for metrics: Total Download Files - $curlTotalUploadFiles on $hostName"

    try {

	    # Network throughput from client VM
        Write-LogMetricsWithCustomProps -MetricsName "Repl_NetworkThroughputTotal_Parallel" -MetricsUnit "Mbps" -MetricsValue $curlNetworkThroughputTotalUp_Parallel -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostName }
	    Write-LogMetricsWithCustomProps -MetricsName "Repl_NetworkThroughputFile_Minimum" -MetricsUnit "Mbps" -MetricsValue $curlBwArrayUpMin -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostName }
	    Write-LogMetricsWithCustomProps -MetricsName "Repl_NetworkThroughputFile_Maximum" -MetricsUnit "Mbps" -MetricsValue $curlBwArrayUpMax -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostName }
	    Write-LogMetricsWithCustomProps -MetricsName "Repl_NetworkThroughputFile_Average" -MetricsUnit "Mbps" -MetricsValue $curlBwArrayUpAvg -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostName }
	    Write-LogMetricsWithCustomProps -MetricsName "Repl_NetworkThroughputFile_Median" -MetricsUnit "Mbps" -MetricsValue $curlBwArrayUpMed -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostName }
	    Write-LogMetricsWithCustomProps -MetricsName "Repl_NetworkThroughputFile_P25" -MetricsUnit "Mbps" -MetricsValue $curlBwUp_P25 -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostName }
	    Write-LogMetricsWithCustomProps -MetricsName "Repl_NetworkThroughputFile_P50" -MetricsUnit "Mbps" -MetricsValue $curlBwUp_P50 -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostName }
	    Write-LogMetricsWithCustomProps -MetricsName "Repl_NetworkThroughputFile_P90" -MetricsUnit "Mbps" -MetricsValue $curlBwUp_P90 -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostName }
	    Write-LogMetricsWithCustomProps -MetricsName "Repl_NetworkThroughputFile_P99" -MetricsUnit "Mbps" -MetricsValue $curlBwUp_P99 -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostName }
	    Write-LogMetricsWithCustomProps -MetricsName "Repl_NetworkThroughputFile_P999" -MetricsUnit "Mbps" -MetricsValue $curlBwUp_P999 -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostName }

	    # Storage read latency from client VM	
        Write-LogMetricsWithCustomProps -MetricsName "Repl_StorageLatency_DataDisk_Avg_Avg" -MetricsUnit $METRIC_UNIT_MilliSeconds -MetricsValue $ReplDDLatencyAvgArrayAvg -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostname }
        Write-LogMetricsWithCustomProps -MetricsName "Repl_StorageLatency_DataDisk_Max_Max" -MetricsUnit $METRIC_UNIT_MilliSeconds -MetricsValue $ReplDDLatencyMaxArrayMax -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostname }
        Write-LogMetricsWithCustomProps -MetricsName "Repl_StorageDiskQueue_DataDisk_Avg_Avg" -MetricsUnit "Queued Requests" -MetricsValue $ReplDDDiskQueueAvgArrayAvg -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostname }
        Write-LogMetricsWithCustomProps -MetricsName "Repl_StorageDiskQueue_DataDisk_Max_Max" -MetricsUnit "Queued Requests" -MetricsValue $ReplDDDiskQueueMaxArrayMax -CheckEndTime $checkEndTime -ThresholdType "Upper" -Props @{"Source" = $hostname }

        # Log check result
        $status="Success"
        $checkEndTime = Get-CurrentTimestamp
	    Write-LogInformation "Snowflake checktool succeeded - Metrics generation - $checkEndTime"

    }
    catch {
        Write-LogError -Message "Unexpected exception occured when running the checktool" -CheckEndTime Get-CurrentTimestamp
	    $checkEndTime = Get-CurrentTimestamp
        Write-LogCheckResultAndExit -MetricsValue $CHECK_FAILURE_WITH_ERROR -CheckEndTime $checkEndTime
    }
}